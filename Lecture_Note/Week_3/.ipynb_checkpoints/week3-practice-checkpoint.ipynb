{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Practice\n",
    "## 과제 안내 \n",
    "- 답안을 작성하여 ipynb 파일로 구글 드라이브 \\[Assignment\\] - \\[개인 폴더\\]로 업로드하시면 됩니다.  \n",
    "- 출력 예시는 각 셀 하단에 수록되어 있습니다.\n",
    "- 출력 결과와 예시가 완전히 일치할 필요는 없습니다! 문제의 조건에만 부합하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Introduction\n",
    "이번 시간에는 붓꽃(IRIS)의 측정 데이터를 활용하여 새로 채집한 붓꽃이 어떤 품종인지 예측할 수 있는 모델을 제작해봅니다.  \n",
    "\n",
    "과정은 아래와 같습니다.  \n",
    "1. 데이터셋 불러오기 및 확인: 붓꽃 데이터셋을 불러오고, 데이터셋의 구조를 파악합니다.  \n",
    "2. 데이터셋 분할: 모델 학습을 위해 불러온 데이터셋을 train data와 validation data로 분할합니다.  \n",
    "3. 모델 학습: 앞서 분할한 데이터를 이용해 모델을 학습시킵니다.  \n",
    "4. 모델 평가: 모델이 올바르게 학습하였는지, 평가해 봅시다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-1 데이터셋 불러오기\n",
    "분류의 대표적인 문제로 \"붓꽃의 품종 분류\"가 있습니다.  \n",
    "위 문제의 목표는 붓꽃의 측정 데이터를 이용해 새로 채집한 붓꽃이 어떤 품종인지\n",
    "예측하여야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "붓꽃 문제의 데이터셋은 scikit-learn의 datasets 모듈에 포함되어 있습니다. 본 데이터셋을 불러오겠습니다. \n",
    "\n",
    "> 붓꽃 이외에도 숫자 손글씨, 당뇨병 등 여러 데이터가 있으니 [링크](https://scikit-learn.org/stable/datasets/index.html)에서 한번 확인해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------keys----------\n",
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris #import IRIS datasets\n",
    "iris_dataset = load_iris()\n",
    "print('--------keys----------')\n",
    "print(iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-1-1\n",
    "- DESCR key에는 데이터셋의 설명이 담겨있습니다. 이를 출력하여 데이터셋 설명을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "### P.4-1-1\n",
    "print(iris_dataset[\"DESCR\"])\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.4-1-1 Comment\n",
    "본 데이터셋에는 꽃받침의 길이, 너비 정보와 꽃잎의 길이, 너비 정보가 주어집니다.  \n",
    " 그리고 Setosa, Versicolor, Virginica 3종류의 꽃이 Labeling 되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-1-2  \n",
    "- 본 데이터셋의 target과 target name을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "### P.4-1-2\n",
    "print(iris_dataset[\"target\"])\n",
    "print(iris_dataset[\"target_names\"])\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-TIPS-1\n",
    "모델을 만들기 전에 어떤 모델이 적합할지, 주어진 데이터가 유효한지, 누락된 값은 없는지 등등 데이터를 분석하고 전처리하는 과정이 필요합니다.  \n",
    "하지만 이번 Practice에서는 본 과정을 생략하겠습니다.  \n",
    "대신 산점도 행렬(Scatter matrix)을 이용하여 데이터셋의 feature들을 시각화하여 데이터를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF14C4E0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BDD85C50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF42F9B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF457F28>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF4884E0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF4B0A58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF4D8FD0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF5055C0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF5055F8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF5600B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF585630>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF5ADBA8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF5E0160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF6066D8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF62EC50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001B3BF65F208>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_train = iris_dataset[\"target\"]\n",
    "X_train = iris_dataset[\"data\"]\n",
    "\n",
    "iris_df = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "pd.plotting.scatter_matrix(iris_df, c=y_train, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-TIPS-1-Comment\n",
    "시각화 결과 품종별로 feature가 잘 구분되는 것을 확인할 수 있습니다.  \n",
    "이제 이 feature 들을 이용하여 모델을 학습시켜 봅시다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-2\n",
    "본격적으로 머신러닝 모델을 만들기 전에 데이터셋을 **train data**와 **valiadation data**로 나누어야 합니다.\n",
    "train/validation/test 데이터가 무엇인지는 [링크](https://lsjsj92.tistory.com/545)를 참고해주세요.\n",
    "\n",
    "\n",
    "Scikit-learn의 train_test_split 함수를 사용하면 편하게 데이터셋을 분할할 수 있습니다.  \n",
    "\n",
    "- iris_dataset을 x_train, x_test, y_train, y_test로 나누어봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train-------\n",
      "[[6.  2.2 4.  1. ]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.1 3.  4.6 1.4]]\n",
      "x_test-------\n",
      "[[5.5 2.6 4.4 1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.  3.5 1.3 0.3]]\n",
      "y_train-------\n",
      "[1 1 1 0 1]\n",
      "y_test-------\n",
      "[1 2 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### P.4-2\n",
    "x = iris_dataset[\"data\"]\n",
    "y = iris_dataset[\"target\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "###\n",
    "print(\"x_train-------\")\n",
    "print(x_train[:5])\n",
    "print(\"x_test-------\")\n",
    "print(x_test[:5])\n",
    "print(\"y_train-------\")\n",
    "print(y_train[:5])\n",
    "print(\"y_test-------\")\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-1\n",
    "Logistic Regression를 이용하여 예측 모델을 제작해 봅시다.\n",
    "- logistic_clf의 이름으로 Logistic Regression 모델을 생성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "### P.4-3-1\n",
    "logistic_clf = LogisticRegression(solver = 'liblinear', multi_class = 'auto')\n",
    "###\n",
    "logistic_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-2\n",
    "- train 데이터를 이용하여 logistic_clf 모델을 학습시켜 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### P.4-3-2\n",
    "logistic_clf.fit(x_train,y_train)\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-3\n",
    "모델의 학습이 잘 진행되었을까요?  한번 간단하게 확인해봅시다!\n",
    "우선 모델이 첫번째 test 데이터를 어떻게 분류하는지 확인해봅시다.\n",
    "- 첫번째 test 데이터의 품종 분류(예측) 결과를 y_pred_example에 저장합니다.\n",
    "- 첫번째 test 데이터의 실제 품종을 y_ans_example에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "### P.4-3-3\n",
    "y_pred_example = logistic_clf.predict(x_test)[0]\n",
    "y_ans_example = y_test[0]\n",
    "###\n",
    "print(y_pred_example)\n",
    "print(y_ans_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-4  \n",
    "위 과정에서 모델이 붓꽃 품종을 올바르게 분류하였나요?  \n",
    "이번에는 모델의 정확도로 알아봅시다! 정확도는 전체 예측 건수에서 정답인 건수의 비율입니다.  \n",
    "scikit-learn에서는 score 함수로 간단하게 정확도를 알 수 있습니다.  \n",
    "logistic_clf의 정확도를 logistic_score에 저장해봅시다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "### P.4-3-4\n",
    "logistic_score = logistic_clf.score(x_test,y_test)\n",
    "###\n",
    "print(\"Accuracy: \", logistic_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-TIPS-2\n",
    "머신러닝 과정에 있어서 모델의 평가는 모델의 학습만큼이나 매우 중요합니다.  \n",
    "모델의 평가를 통해 이 모델이 적절한지, 모델의 학습이 잘 이루어졌는지, hyperparameter를 어떻게 조정할지 등등을 결정할 수 있습니다.  \n",
    "하지만 정확도(Accuracy)만으로 모델을 평가할 수는 없습니다. 그 이유는 무엇일까요? \n",
    "- [링크](https://velog.io/@skyepodium/%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95)에서 모델을 평가하는 지표인 accuracy, precision, f1 score 등에 대해서 알아봅시다. \n",
    "- 또한 [링크](https://m.blog.naver.com/PostView.nhn?blogId=ckdgus1433&logNo=221599517834&proxyReferer=https:%2F%2Fwww.google.com%2F)에서 모델 평가에 사용되는 기법인 교차 검증(Cross-Validation)에 대해서도 알아봅시다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-5\n",
    "- 앞서 만든 logistic_clf 모델에 대해서 5번의 k-fold 교차검증을 시행하고, 각 단계에서의 accuracy를 출력하여 봅시다.\n",
    "- 각 단계에서의 accuracy의 평균을 출력하여 봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95833333 0.91304348 0.95454545 0.95454545 0.95238095]\n",
      "0.9465697346132128\n"
     ]
    }
   ],
   "source": [
    "### P.4-3-5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logistic_clf,x_train,y_train,cv = 5)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-6   \n",
    "logistic_clf 모델의 혼동 행렬(confusion Matrix)를 그려봅시다.  \n",
    "혼돈 행렬에 대한 설명은 (링크)[https://m.blog.naver.com/kmkim1222/220106232149]를 참고해주세요.  \n",
    "더불어 seaborn의 heatmap을 이용하여 보기 좋게 시각화하여 봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### P.4-3-6\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pred = logistic_clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "plt.pcolor(cm)\n",
    "plt.show()\n",
    "\n",
    "### P.4-3-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-3-7\n",
    "- logistic_clf 모델의 accuracy, precision, recall, f1 score를 구해 봅시다. 이때 macro average를 이용합니다.\n",
    "\n",
    "macro average와 micro average 설명은 [링크](https://unlimitedpower.tistory.com/entry/IR-%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C-%ED%8F%89%EA%B7%A0Micro-average-%EB%A7%A4%ED%81%AC%EB%A1%9C-%ED%8F%89%EA%B7%A0Macro-average-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80)를 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9473684210526315\n",
      "precision_score:  0.9583333333333334\n",
      "recall_score:  0.9393939393939394\n",
      "f1_score:  0.9444444444444443\n"
     ]
    }
   ],
   "source": [
    "### P.4-3-7\n",
    "acc_score  = metrics.accuracy_score(y_test, pred)\n",
    "prec_score  = metrics.precision_score(y_test, pred, average = 'macro')\n",
    "rec_score  = metrics.recall_score(y_test, pred, average = 'macro')\n",
    "f1_score  = metrics.f1_score(y_test, pred, average = 'macro')\n",
    "###\n",
    "print(\"accuracy_score: \", acc_score)\n",
    "print(\"precision_score: \", prec_score)\n",
    "print(\"recall_score: \", rec_score)\n",
    "print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.4-4\n",
    "- 앞서 배운 분류 알고리즘 SVM, Decision Tree, KNN에 대해서도 위 모델 학습/평가 과정을 시행해봅시다.\n",
    "- 붓꽃 분류 문제에서는 어떤 모델이 가장 적합할까요? 한번 찾아봅시다! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm 평균점수 :  0.9822134387351777\n",
      "DTC 평균점수 :  0.9469320534537926\n",
      "KNN 평균점수 :  0.9639939770374554\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "svm_clf = svm.SVC(kernel = 'linear')\n",
    "svm_clf.fit(x_train,y_train)\n",
    "svm_clf.score(x_test,y_test)\n",
    "svm_scores = cross_val_score(svm_clf,x_train,y_train,cv = 5)\n",
    "print('svm 평균점수 : ',svm_scores.mean())\n",
    "\n",
    "DTC_clf = DecisionTreeClassifier(random_state = 0)\n",
    "DTC_clf.fit(x_train, y_train)\n",
    "DTC_clf.score(x_test,y_test)\n",
    "DTC_scores = cross_val_score(DTC_clf,x_train,y_train,cv = 5)\n",
    "print('DTC 평균점수 : ',DTC_scores.mean())\n",
    "\n",
    "KNN_clf = KNeighborsClassifier()\n",
    "KNN_clf.fit(x_train, y_train)\n",
    "KNN_clf.score(x_test,y_test)\n",
    "KNN_scores = cross_val_score(KNN_clf,x_train,y_train,cv = 5)\n",
    "print('KNN 평균점수 : ',KNN_scores.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
